{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class for easier runtime calculations\n",
    "\n",
    "class timer:\n",
    "    def __init__(self):\n",
    "        self._start = time.time()\n",
    "        self._end = None\n",
    "        self._runtime = None\n",
    "    \n",
    "    def end(self):\n",
    "        self._end = time.time()\n",
    "        self._runtime = float(str(time.time() - self._start)[:5])\n",
    "        return self._runtime\n",
    "\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "USERNAME = \"neo4j\"\n",
    "PASSWORD = \"\"\n",
    "\n",
    "# Helper function that runs cypher transaction on local database\n",
    "def cypher_transaction(cypher):\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(USERNAME,  PASSWORD))\n",
    "    values = []\n",
    "    with driver.session() as session:\n",
    "        res = session.run(cypher)\n",
    "        for record in res:\n",
    "            values.append(record.values())\n",
    "    driver.close()\n",
    "    return values\n",
    "\n",
    "# Helper function wrapped around cypher_transaction() for timing\n",
    "def query(cypher):\n",
    "    time = timer()\n",
    "    result = cypher_transaction(cypher)\n",
    "    runtime = time.end()\n",
    "    return result, runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get type and number of each FHIR resource in the database\n",
    "def resource_metrics():\n",
    "    \n",
    "    cypher = f'''\n",
    "        MATCH (r:resource) \n",
    "        WITH DISTINCT(r.resourceType) AS resource_types\n",
    "            ORDER BY resource_types\n",
    "        UNWIND resource_types as resource_type\n",
    "        MATCH (r:resource)\n",
    "        WHERE r.resourceType = resource_type\n",
    "        WITH resource_type, COUNT(r) as resource_count\n",
    "        RETURN resource_type, resource_count\n",
    "            ORDER BY resource_count\n",
    "    '''\n",
    "\n",
    "    resource_count, runtime = query(cypher)\n",
    "    return resource_count\n",
    "    \n",
    "# Standard metrics for counting nodes and relationships\n",
    "def database_metrics():\n",
    "    node_count = 0\n",
    "    relationship_count = 0\n",
    "    \n",
    "    cypher = f'''\n",
    "        MATCH (n) \n",
    "        WITH COUNT(n) as node_count\n",
    "        MATCH ()-[r]->()\n",
    "        WITH node_count, COUNT(r) as relationship_count\n",
    "        RETURN node_count, relationship_count\n",
    "    '''\n",
    "    \n",
    "    count_result, runtime = query(cypher)\n",
    "    if (len(count_result) != 0):\n",
    "        node_count = count_result[0][0]\n",
    "        relationship_count = count_result[0][1]\n",
    "    \n",
    "    return node_count, relationship_count\n",
    "    \n",
    "# Deletes all nodes and their relationships in database\n",
    "def wipe_database():\n",
    "    node_count, relationship_count = database_metrics()\n",
    "    \n",
    "    cypher = f'''\n",
    "        MATCH (n) DETACH DELETE n\n",
    "    '''\n",
    "\n",
    "    delete_result, runtime = query(cypher)\n",
    "    return 'Deleted {} nodes and {} relationships in {} seconds'.format( node_count, relationship_count, runtime )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wipe_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    with open(filename) as json_file:\n",
    "        bundle = json.load(json_file)\n",
    "        bundle_string = json.dumps(bundle)\n",
    "        bundle_string_formatted = re.sub(r'\"', '\\\\\"', bundle_string)\n",
    "        return bundle_string_formatted\n",
    "\n",
    "# Calls cyfhir.bundle.load() to load in patient medical histories via FHIR bundles\n",
    "def load_bundles(synthea_bundles):\n",
    "    total_time = 0.0\n",
    "    for file in range(len(synthea_bundles)):\n",
    "        bundle_string = read_json(synthea_bundles[file])\n",
    "\n",
    "        cypher = f'''\n",
    "            CALL cyfhir.bundle.load(\"{bundle_string}\")\n",
    "        '''\n",
    "        \n",
    "        patient = ' '.join(synthea_bundles[file].split('/')[2].split('_')[:2])\n",
    "        result, runtime = query(cypher)\n",
    "        print('--- Loaded patient \"{}\" in {} seconds ---'.format( patient , runtime))\n",
    "        total_time += runtime\n",
    "        \n",
    "    return round(total_time, 3)\n",
    "    \n",
    "synthea_bundles = glob.glob(\"./synthea-bundles/*.json\")\n",
    "synthea_bundles.sort()\n",
    "total_time = load_bundles(synthea_bundles)\n",
    "resource_result = np.array(resource_metrics())\n",
    "total_resources = np.sum([int(x) for x in resource_result[:,1]])\n",
    "node_count, relationship_count = database_metrics()\n",
    "\n",
    "print(\"\\nIn {} seconds...\".format(total_time))\n",
    "print(\"Loaded 20 Patient's Medical Histories as FHIR Bundles\".format(len(synthea_bundles)))\n",
    "print(\"Which Contained {} total FHIR Resources\".format(total_resources))\n",
    "print(\"For a total of {} Nodes and {} Relationships in Neo4j\".format(node_count, relationship_count))\n",
    "\n",
    "print(\"At a rate of {} resources per second\".format(round(total_resources/total_time, 3)))\n",
    "print(\"Each resource has an average of {} Nodes and {} Relationships\".format(round(node_count/total_resources, 3), round(relationship_count/total_resources, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(resource_result, columns = [\"resourceType\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Occurances of which FHIR Resources directly point to other kinds of FHIR resources\n",
    "def reference_metrics():\n",
    "    \n",
    "    cypher = f'''\n",
    "        MATCH (a:resource)-[*1..4]->(b:resource)\n",
    "        WITH [a.resourceType, b.resourceType] AS path\n",
    "        RETURN distinct(path) AS nodes, count(path) AS path_count\n",
    "    '''\n",
    "\n",
    "    reference_count, runtime = query(cypher)\n",
    "    return reference_count\n",
    "\n",
    "path_metrics = reference_metrics()\n",
    "as_array = [[x[0][0],x[0][1], x[1]] for x in path_metrics]\n",
    "df_references = pd.DataFrame(as_array, columns=[\"Resource\", \"References\", \"Count\"])\n",
    "df_references.sort_values([\"Count\"], inplace=True, ascending=False, ignore_index=True)\n",
    "df_references.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Function that Deep sorts all the keys of a json and returns it as an object for comparison\n",
    "def ordered(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return sorted((k, ordered(v)) for k, v in obj.items())\n",
    "    if isinstance(obj, list):\n",
    "        return sorted(ordered(x) for x in obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Find resource by matching 'resource.id', expand out all of its properties, format, and return\n",
    "def get_resource(_id):\n",
    "    \n",
    "    cypher = '''\n",
    "        WITH \"%s\" as _id\n",
    "        MATCH (r:resource {id: _id})\n",
    "        CALL cyfhir.resource.expand(r) YIELD path\n",
    "        WITH cyfhir.resource.format(collect(path)) AS resource\n",
    "        RETURN resource\n",
    "    ''' % _id\n",
    "    \n",
    "    resource, runtime = query(cypher)\n",
    "    return resource, runtime, cypher\n",
    "\n",
    "# Deep sort FHIR Resources, return matching string if/if not equivalent\n",
    "def equivalency_test(json1, json2):\n",
    "    equivalent = ordered(json1) == ordered(json2) \n",
    "    if(equivalent):\n",
    "        return ' equivalent' \n",
    "    else:\n",
    "        return ' not equivalent'\n",
    "\n",
    "\n",
    "bundle_file = \"./synthea-bundles/Theola421_Haag279_6aff2910-82fc-44d6-84a6-c29e4b756b11.json\"\n",
    "bundle = None\n",
    "with open(bundle_file) as json_file:\n",
    "        bundle = json.load(json_file)\n",
    "        \n",
    "patient_resource = bundle.get('entry')[0]['resource']\n",
    "_id = patient_resource['id']\n",
    "resource, runtime, cypher = get_resource(_id)\n",
    "resource_result = resource[0][0]\n",
    "\n",
    "print(cypher)\n",
    "print('Resources are' + equivalency_test(patient_resource, resource_result))\n",
    "#print(json.dumps(resource_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to getting a resource but you want to collect the Resource \"Entry\" Nodes that are created\n",
    "# These are used to create the FHIR Bundle\n",
    "# This query build a bundle of resources that directly point to or are directly pointed to \n",
    "# by a single resource with id matching '_id'\n",
    "# [(resource)]->(resource {id: _id})->[(resource)]\n",
    "def get_bundle(_id): \n",
    "    cypher = '''\n",
    "        WITH \"%s\" as _id\n",
    "        MATCH (_entry:entry {_resourceId: _id})\n",
    "        WITH [_entry] + [(a:entry)-[*1..3]->(_entry) | a] + [(_entry)-[*1..3]->(a:entry) | a] as entries\n",
    "        WITH DISTINCT(entries) AS entries\n",
    "        UNWIND entries AS entry\n",
    "        CALL cyfhir.resource.expand(entry) YIELD path\n",
    "        RETURN cyfhir.bundle.format(collect(path))\n",
    "        ''' % _id\n",
    "\n",
    "    resource, runtime = query(cypher)\n",
    "    return resource, runtime\n",
    "\n",
    "bundle_file = \"./synthea-bundles/Theola421_Haag279_6aff2910-82fc-44d6-84a6-c29e4b756b11.json\"\n",
    "bundle = None\n",
    "with open(bundle_file) as json_file:\n",
    "        bundle = json.load(json_file)\n",
    "        \n",
    "_id = bundle.get('entry')[0]['resource']['id']\n",
    "bundle_result, runtime = get_bundle(_id)\n",
    "bundle_result=bundle_result[0][0]\n",
    "\n",
    "print('Bundles are' + equivalency_test(bundle, bundle_result))\n",
    "print('Runtime: ' + str(runtime))\n",
    "print(len(bundle_result['entry']))\n",
    "#print(json.dumps(bundle_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the previous function but this time it takes matching resources\n",
    "# and then finds all the resources that directly point to or are directly pointed to \n",
    "# by those entries, creating a bundle with a 2nd layer around the center node. \n",
    "def get_deeper_bundle(_id):\n",
    "    cypher = '''\n",
    "        WITH \"%s\" as _id\n",
    "        MATCH (_entry:entry {_resourceId: _id})\n",
    "        WITH [_entry] + [(a:entry)-[*1..4]->(_entry) | a] + [(_entry)-[*1..4]->(a:entry) | a] as entries\n",
    "        WITH entries AS entries\n",
    "        UNWIND entries AS _entry\n",
    "        WITH [_entry] + [(a:entry)-[*1..4]->(_entry) | a] + [(_entry)-[*1..4]->(a:entry) | a] as entries\n",
    "        UNWIND entries AS _entry\n",
    "        WITH DISTINCT(_entry) AS entry\n",
    "        CALL cyfhir.resource.expand(entry) YIELD path\n",
    "        RETURN cyfhir.bundle.format(collect(path))\n",
    "        ''' % _id\n",
    "\n",
    "    resource, runtime = query(cypher)\n",
    "    return resource, runtime\n",
    "\n",
    "bundle_file = \"./synthea-bundles/Antone63_Lebsack687_a7fefb0a-e326-b7ef-ce3c-2f97e77f15c7.json\"\n",
    "bundle = None\n",
    "with open(bundle_file) as json_file:\n",
    "        bundle = json.load(json_file)\n",
    "        \n",
    "_id = bundle.get('entry')[0]['resource']['id']\n",
    "bundle_shallow, runtime1 = get_bundle(_id)\n",
    "bundle_shallow=bundle_shallow[0][0]\n",
    "\n",
    "bundle_deep, runtime2 = get_deeper_bundle(_id)\n",
    "bundle_deep=bundle_deep[0][0]\n",
    "\n",
    "print('Bundles are' + equivalency_test(bundle_shallow, bundle_deep))\n",
    "print(len(bundle_shallow['entry']), len(bundle_deep['entry']))\n",
    "print(\"Runtime Shallow: \" + str(runtime1) + \"\\nRuntime Deep: \" + str(runtime2))\n",
    "#print(json.dumps(bundle_deep, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collects all Possible conditions per \"Condition\" Resource, finds all conditions a patient\n",
    "# is associated with, then One hot encodes all of the patient's conditions\n",
    "def patient_conditions_encoded():\n",
    "    \n",
    "    cypher = '''\n",
    "        MATCH path=((r:resource {resourceType: \"Condition\"})-[*2]->(c:coding))\n",
    "        WITH distinct(c.display) as _display\n",
    "          ORDER BY _display\n",
    "        RETURN _display\n",
    "    '''\n",
    "\n",
    "    conditions, runtime = query(cypher)\n",
    "    \n",
    "    cypher = '''\n",
    "        MATCH path=((r:resource {resourceType: \"Condition\"})-[*2]->(c:coding))\n",
    "        WITH distinct(c.display) as _display\n",
    "          ORDER BY _display\n",
    "        WITH _display, collect(_display) AS _displays\n",
    "        MATCH (patient:resource {resourceType: \"Patient\"})\n",
    "        WITH patient.id AS Patient_ID, gds.alpha.ml.oneHotEncoding(_displays, [(coding{display: _display})<-[*2]-(r:resource {resourceType: \"Condition\"})-[*1..3]->(patient) | _display]) AS embedding\n",
    "        UNWIND embedding as embed\n",
    "        WITH Patient_ID, collect(embed) as Condition_Embeddings\n",
    "        RETURN Patient_ID, Condition_Embeddings\n",
    "          ORDER BY Patient_ID\n",
    "        '''\n",
    "\n",
    "    encodings, runtime = query(cypher)\n",
    "    return conditions, encodings, runtime\n",
    "\n",
    "conditions, encodings, runtime = patient_conditions_encoded()\n",
    "condition_names = np.hstack((np.array([\"Patient_ID\"]), np.array(conditions).T[0]))\n",
    "condition_names = condition_names[condition_names != None]\n",
    "\n",
    "patients = np.array([[x[0]] for x in encodings])\n",
    "conditions_encoded = np.array([x[1] for x in encodings])\n",
    "\n",
    "table = np.hstack((patients, conditions_encoded))\n",
    "print(table[0:2])\n",
    "print(\"Runtime: \" + str(runtime))\n",
    "display(pd.DataFrame(table, columns=list(condition_names)).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_native_projection():\n",
    "    \n",
    "    cypher = '''\n",
    "        CALL gds.graph.drop('referenceGraph') YIELD graphName;\n",
    "        '''\n",
    "\n",
    "    result, runtime = query(cypher)\n",
    "    return result, runtime\n",
    "\n",
    "# Finds all paths in which a resource points to another resource\n",
    "# It then finds all the node labels and relationship types in those paths\n",
    "# Using those two lists we can create a Native Projection of all of the resource references without any of the other \n",
    "# information we may not need\n",
    "def create_native_projection():\n",
    "    try:\n",
    "        delete_native_projection()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    cypher = '''\n",
    "        Match path=((a:resource)-[*1..4]->(b:resource))\n",
    "        WITH path\n",
    "        CALL {\n",
    "            WITH path\n",
    "            WITH nodes(path) AS _nodes\n",
    "            UNWIND _nodes AS _node\n",
    "            WITH DISTINCT(labels(_node)[0]) AS _label\n",
    "            RETURN collect(_label) AS _labels\n",
    "        }\n",
    "        WITH path, _labels\n",
    "        CALL {\n",
    "            WITH path\n",
    "            WITH relationships(path) AS _relationships\n",
    "            UNWIND _relationships AS _relationship\n",
    "            WITH DISTINCT(type(_relationship)) AS _type\n",
    "            RETURN collect(_type) AS _types\n",
    "        }\n",
    "        WITH _labels, _types\n",
    "        UNWIND _labels AS _label\n",
    "        UNWIND _types AS _type\n",
    "        WITH collect(DISTINCT(_label)) AS label, collect(DISTINCT(_type)) AS type\n",
    "        CALL gds.graph.create(\"referenceGraph\", label, type) YIELD graphName, nodeCount, relationshipCount\n",
    "        RETURN graphName, nodeCount, relationshipCount\n",
    "        '''\n",
    "\n",
    "    result, runtime = query(cypher)\n",
    "    return result, runtime\n",
    "\n",
    "result, runtime = create_native_projection()\n",
    "graphName, nodeCount, relationshipCount = (result[0][0], result[0][1], result[0][2])\n",
    "print(graphName, nodeCount, relationshipCount, \"| runtime: \"+ str(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Rank Resource nodes to find most relevant nodes in database\n",
    "def page_rank_nodes():\n",
    "    \n",
    "    cypher = '''\n",
    "        CALL gds.pageRank.stream('referenceGraph', \n",
    "            { dampingFactor: 0.868378238, maxIterations: 52, tolerance: 0.00001 })\n",
    "        YIELD nodeId, score\n",
    "        WITH gds.util.asNode(nodeId) AS node, score\n",
    "        WHERE labels(node)[0] = \"resource\"\n",
    "        WITH node.id AS resourceId, node.resourceType AS resourceType, score\n",
    "        RETURN resourceId, resourceType, score\n",
    "        ORDER BY score DESC\n",
    "        '''\n",
    "\n",
    "    result, runtime = query(cypher)\n",
    "    return result, runtime\n",
    "\n",
    "result, runtime = page_rank_nodes()\n",
    "df = pd.DataFrame(result, columns = ['resourceId', 'resourceType', 'score'])\n",
    "display(df.head(10), \"runtime: \"+ str(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betweenness Centrality on nodes to find bridge nodes in database\n",
    "def betweenness_centrality():\n",
    "    \n",
    "    cypher = '''\n",
    "        CALL gds.betweenness.stream('referenceGraph')\n",
    "        YIELD nodeId, score\n",
    "        WITH gds.util.asNode(nodeId) AS node, score\n",
    "        WHERE labels(node)[0] = \"resource\"\n",
    "        WITH node.id AS resourceId, node.resourceType AS resourceType, score\n",
    "        RETURN resourceId, resourceType, score\n",
    "        ORDER BY score DESC\n",
    "        '''\n",
    "\n",
    "    result, runtime = query(cypher)\n",
    "    return result, runtime\n",
    "\n",
    "result, runtime = betweenness_centrality()\n",
    "df = pd.DataFrame(result, columns = ['resourceId', 'resourceType', 'score'])\n",
    "display(df.head(10), \"runtime: \"+ str(runtime))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node2vec on Nodes\n",
    "def node2vec():\n",
    "    \n",
    "    cypher = '''\n",
    "    CALL gds.alpha.node2vec.stream('referenceGraph', {\n",
    "            embeddingSize: 2, \n",
    "            iterations: 4, \n",
    "            walkLength: 128,\n",
    "            walksPerNode: 16,\n",
    "            windowSize: 16\n",
    "        })\n",
    "    YIELD nodeId, embedding\n",
    "    WITH gds.util.asNode(nodeId) AS node, embedding\n",
    "    WHERE labels(node)[0] = \"resource\"\n",
    "    WITH node.id AS resourceId, node.resourceType AS resourceType, embedding\n",
    "    RETURN resourceId, resourceType, embedding\n",
    "    ORDER BY sqrt(embedding[0]*embedding[0] + embedding[1]*embedding[1])\n",
    "    '''\n",
    "\n",
    "    result, runtime = query(cypher)\n",
    "    return result, runtime\n",
    "\n",
    "result, runtime = node2vec()\n",
    "df = pd.DataFrame(result, columns = ['resourceId', 'resourceType', 'embedding'])\n",
    "display(df.head(10), \"runtime: \"+ str(runtime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "#display(df.head(num))\n",
    "embedding = df['embedding'].values\n",
    "embedding = np.array([[x[0], x[1]] for x in embedding])[:num]\n",
    "X, Y = (embedding[:,0],embedding[:,1])\n",
    "_min, _max = (min(X), max(X))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(X, Y,'b.')\n",
    "plt.axhline(linewidth=2, color='black')\n",
    "plt.axvline(linewidth=2, color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds every patients previous medical conditions, medications, procedures, physicians, and organizations they have visited\n",
    "def patient_history():\n",
    "    \n",
    "    cypher = '''\n",
    "    MATCH (p:resource {resourceType: \"Patient\"})\n",
    "    WITH collect(p) as patients\n",
    "    UNWIND patients as patient\n",
    "    CALL{\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Condition\"})-[*1]->(c:code))\n",
    "      WITH DISTINCT(c.text) as _text, patient\n",
    "        ORDER BY _text\n",
    "      WITH patient, _text, collect(_text) AS _texts\n",
    "      WITH patient, [(code{text: _text})<-[*1]-(r:resource {resourceType: \"Condition\"})-[*1..3]->(patient) | _text] AS embedding\n",
    "      UNWIND embedding as embed\n",
    "      WITH collect(DISTINCT(embed)) as conditions\n",
    "      RETURN conditions\n",
    "    }\n",
    "    WITH patient, conditions\n",
    "    CALL{\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Organization\"}))\n",
    "      WITH DISTINCT(r.name) as _name, patient\n",
    "        ORDER BY _name\n",
    "      WITH patient, _name, collect(_name) AS _names\n",
    "      WITH patient, [(s:serviceProvider {display: _name})<-[*1]-(r:resource {resourceType: \"Encounter\"})-[*1..3]->(patient) | _name] AS embedding\n",
    "      UNWIND embedding as embed\n",
    "      WITH collect(DISTINCT(embed)) as organizations\n",
    "      RETURN organizations\n",
    "    }\n",
    "    WITH patient, conditions, organizations\n",
    "    CALL{\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Encounter\"})-[*2]->(i:individual))\n",
    "      WITH DISTINCT(i.display) as _display, patient\n",
    "        ORDER BY _display\n",
    "      WITH patient, _display, collect(_display) AS _displays\n",
    "      WITH patient, [(individual{display: _display})<-[*2]-(r:resource {resourceType: \"Encounter\"})-[*1..3]->(patient) | _display] AS embedding\n",
    "      UNWIND embedding as embed\n",
    "      WITH collect(DISTINCT(embed)) as practitioners\n",
    "      RETURN practitioners\n",
    "    }\n",
    "    WITH patient, conditions, organizations, practitioners\n",
    "    CALL{\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"MedicationRequest\"})-[*1]->(m:medicationCodeableConcept))\n",
    "      WITH DISTINCT(m.text) as _text, patient\n",
    "        ORDER BY _text\n",
    "      WITH patient, _text, collect(_text) AS _texts\n",
    "      WITH patient, [(medicationCodeableConcept{text: _text})<-[*1]-(r:resource {resourceType: \"MedicationRequest\"})-[*1..3]->(patient) | _text] AS embedding\n",
    "      UNWIND embedding as embed\n",
    "      WITH collect(DISTINCT(embed)) as medications\n",
    "      RETURN medications\n",
    "    }\n",
    "    WITH patient, conditions, organizations, practitioners, medications\n",
    "    CALL{\n",
    "     WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Procedure\"})-[*1]->(c:code))\n",
    "      WITH DISTINCT(c.text) as _text, patient\n",
    "        ORDER BY _text\n",
    "      WITH patient, _text, collect(_text) AS _texts\n",
    "      WITH patient, [(code{text: _text})<-[*1]-(r:resource {resourceType: \"Procedure\"})-[*1..3]->(patient) | _text] AS embedding\n",
    "      UNWIND embedding as embed\n",
    "      WITH collect(DISTINCT(embed)) as procedures\n",
    "      RETURN procedures\n",
    "    }\n",
    "    RETURN patient.id, conditions, organizations, practitioners, medications, procedures\n",
    "    '''\n",
    "\n",
    "    result, runtime = query(cypher)\n",
    "    return result, runtime\n",
    "\n",
    "\n",
    "result, runtime = patient_history()\n",
    "df = pd.DataFrame(result, columns=[\"patient\", \"conditions\", \"organizations\", \"practitioners\", \"medications\", \"procedures\"]).head(2)\n",
    "display(df)\n",
    "print(df.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes info from above (same beginning portion of query) and one hot encodes/indexes it for each pair of patients, including same patients to show\n",
    "# that it is for the most part working, then runs jaccard similarity on them to find a flat patient similarity in medical history\n",
    "def patient_similarity():\n",
    "    cypher = '''\n",
    "    MATCH (p:resource {resourceType: \"Patient\"})\n",
    "    WITH collect(p) AS patients\n",
    "    UNWIND patients AS patient\n",
    "    CALL {\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Condition\"})-[*1]->(c:code))\n",
    "      WITH DISTINCT(c.text) AS _text, patient\n",
    "        ORDER BY _text\n",
    "      WITH patient, _text, collect(_text) AS _texts\n",
    "      WITH patient, [(code{text: _text})<-[*1]-(r:resource {resourceType: \"Condition\"})-[*1..3]->(patient) | _text] AS embedding\n",
    "      UNWIND embedding AS embed\n",
    "      WITH collect(DISTINCT(embed)) AS conditions\n",
    "      RETURN conditions\n",
    "    }\n",
    "    WITH patient, conditions\n",
    "    CALL {\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Organization\"}))\n",
    "      WITH DISTINCT(r.name) AS _name, patient\n",
    "        ORDER BY _name\n",
    "      WITH patient, _name, collect(_name) AS _names\n",
    "      WITH patient, [(s:serviceProvider {display: _name})<-[*1]-(r:resource {resourceType: \"Encounter\"})-[*1..3]->(patient) | _name] AS embedding\n",
    "      UNWIND embedding AS embed\n",
    "      WITH collect(DISTINCT(embed)) AS organizations\n",
    "      RETURN organizations\n",
    "    }\n",
    "    WITH patient, conditions, organizations\n",
    "    CALL {\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Encounter\"})-[*2]->(i:individual))\n",
    "      WITH DISTINCT(i.display) AS _display, patient\n",
    "        ORDER BY _display\n",
    "      WITH patient, _display, collect(_display) AS _displays\n",
    "      WITH patient, [(individual{display: _display})<-[*2]-(r:resource {resourceType: \"Encounter\"})-[*1..3]->(patient) | _display] AS embedding\n",
    "      UNWIND embedding AS embed\n",
    "      WITH collect(DISTINCT(embed)) AS practitioners\n",
    "      RETURN practitioners\n",
    "    }\n",
    "    WITH patient, conditions, organizations, practitioners\n",
    "    CALL {\n",
    "      WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"MedicationRequest\"})-[*1]->(m:medicationCodeableConcept))\n",
    "      WITH DISTINCT(m.text) AS _text, patient\n",
    "        ORDER BY _text\n",
    "      WITH patient, _text, collect(_text) AS _texts\n",
    "      WITH patient, [(medicationCodeableConcept{text: _text})<-[*1]-(r:resource {resourceType: \"MedicationRequest\"})-[*1..3]->(patient) | _text] AS embedding\n",
    "      UNWIND embedding AS embed\n",
    "      WITH collect(DISTINCT(embed)) AS medications\n",
    "      RETURN medications\n",
    "    }\n",
    "    WITH patient, conditions, organizations, practitioners, medications\n",
    "    CALL {\n",
    "     WITH patient\n",
    "      MATCH path=((r:resource {resourceType: \"Procedure\"})-[*1]->(c:code))\n",
    "      WITH DISTINCT(c.text) AS _text, patient\n",
    "        ORDER BY _text\n",
    "      WITH patient, _text, collect(_text) AS _texts\n",
    "      WITH patient, [(code{text: _text})<-[*1]-(r:resource {resourceType: \"Procedure\"})-[*1..3]->(patient) | _text] AS embedding\n",
    "      UNWIND embedding AS embed\n",
    "      WITH collect(DISTINCT(embed)) AS procedures\n",
    "      RETURN procedures\n",
    "    }\n",
    "    WITH patient, patient.id AS patientId, conditions + organizations + practitioners + medications + procedures AS medical_history\n",
    "    WITH patient, medical_history, [patientId, medical_history] AS pair\n",
    "    WITH collect(pair) AS pairs1, collect(pair) AS pairs2\n",
    "    WITH pairs1, pairs2, [] AS complete\n",
    "    UNWIND pairs1 AS pair1\n",
    "    UNWIND pairs2 AS pair2\n",
    "    WITH pair1[0] AS id1, pair2[0] AS id2, pair1[1] AS history1, pair2[1] AS history2\n",
    "    CALL { \n",
    "      WITH id1, history1, id2, history2\n",
    "      WITH DISTINCT(history1+history2) AS list, history1, history2\n",
    "      WITH gds.alpha.ml.oneHotEncoding(list, history1) AS list1, gds.alpha.ml.oneHotEncoding(list, history2) AS list2, history1, history2\n",
    "      WITH size(list1) AS len, list1, list2\n",
    "      WITH [x IN range(0,len) WHERE list1[x] = 1 ] AS encoding1, [x IN range(0,len) WHERE list2[x] = 1 ] AS encoding2\n",
    "      RETURN gds.alpha.similarity.jaccard(encoding1, encoding2) AS similarity\n",
    "    }\n",
    "    RETURN id1, id2, similarity\n",
    "      ORDER BY similarity DESC\n",
    "    '''\n",
    "    \n",
    "    result, runtime = query(cypher)\n",
    "    return result, runtime\n",
    "\n",
    "result, runtime = patient_similarity()\n",
    "print(\"runtime: \"+ str(runtime))\n",
    "pd.DataFrame(result, columns=[\"id1\", \"id2\", \"similarity\"]).iloc[17:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
